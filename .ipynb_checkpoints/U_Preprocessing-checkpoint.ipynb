{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1ea2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b76016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fergu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d43eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\fergu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672e9753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fergu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "010e2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def func_lemmatize(words):\n",
    "    lemmatized = []\n",
    "    for word, tag in pos_tag(words):\n",
    "        wntag = tag[0].lower()\n",
    "        wntag = wntag if wntag in ['a','r','n','v'] else None\n",
    "        \n",
    "        lemma = wnl.lemmatize(word,wntag) if wntag else word\n",
    "        lemmatized.append(lemma)\n",
    "    return lemmatized\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "pattern = r'(\\w+)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eba502",
   "metadata": {},
   "source": [
    "### Other Lemmatizing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbf0cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## def func_lemmatize(words):\n",
    "##     allow = ['a','r','n','v']\n",
    "##     \n",
    "## #    list_1 = [(word,tag[0].lower() if tag[0].lower() in allow else None) for word,tag in pos_tag(words)]\n",
    "##     list_2 = [wnl.lemmatize(word,wntag) if wntag else word for word, wntag in [(word,tag[0].lower() if tag[0].lower() in allow else None) for word,tag in pos_tag(words)]]\n",
    "##     \n",
    "##     return list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f13f7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## def func_lemmatize(words):\n",
    "##     allow = ['a','r','n','v']\n",
    "##     \n",
    "##     list_1 = [(word,tag[0].lower() if tag[0].lower() in allow else None) for word,tag in pos_tag(words)]\n",
    "##     list_2 = [wnl.lemmatize(word,wntag) if wntag else word for word, wntag in list_1]\n",
    "##     \n",
    "##     return list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801085be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## def func_lemmatize(words):\n",
    "##     allow = ['a','r','n','v']\n",
    "##     \n",
    "##     lemmatized = [wntag if wntag[0].lower() in allow for word,tag in pog_tag(words)]\n",
    "##     lemma = [wnl.lemmatize(item) for item in list_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057aceb",
   "metadata": {},
   "source": [
    "### /Other Lemmatizing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187581c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>url</th>\n",
       "      <th>section</th>\n",
       "      <th>publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-09 18:31:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Lee Drutman</td>\n",
       "      <td>We should take concerns about the health of li...</td>\n",
       "      <td>This post is part of Polyarchy, an independent...</td>\n",
       "      <td>https://www.vox.com/polyarchy/2016/12/9/138983...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-07 21:26:46</td>\n",
       "      <td>2016</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Scott Davis</td>\n",
       "      <td>Colts GM Ryan Grigson says Andrew Luck's contr...</td>\n",
       "      <td>The Indianapolis Colts made Andrew Luck the h...</td>\n",
       "      <td>https://www.businessinsider.com/colts-gm-ryan-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Insider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-26 00:00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump denies report he ordered Mueller fired</td>\n",
       "      <td>DAVOS, Switzerland (Reuters) - U.S. President ...</td>\n",
       "      <td>https://www.reuters.com/article/us-davos-meeti...</td>\n",
       "      <td>Davos</td>\n",
       "      <td>Reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-06-27 00:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France's Sarkozy reveals his 'Passions' but in...</td>\n",
       "      <td>PARIS (Reuters) - Former French president Nico...</td>\n",
       "      <td>https://www.reuters.com/article/france-politic...</td>\n",
       "      <td>World News</td>\n",
       "      <td>Reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-27 00:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris Hilton: Woman In Black For Uncle Monty's...</td>\n",
       "      <td>Paris Hilton arrived at LAX Wednesday dressed ...</td>\n",
       "      <td>https://www.tmz.com/2016/01/27/paris-hilton-mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TMZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Unnamed: 0.1                 date  year  month day       author  \\\n",
       "0           0            0  2016-12-09 18:31:00  2016   12.0   9  Lee Drutman   \n",
       "1           1            1  2016-10-07 21:26:46  2016   10.0   7  Scott Davis   \n",
       "2           2            2  2018-01-26 00:00:00  2018    1.0  26          NaN   \n",
       "3           3            3  2019-06-27 00:00:00  2019    6.0  27          NaN   \n",
       "4           4            4  2016-01-27 00:00:00  2016    1.0  27          NaN   \n",
       "\n",
       "                                               title  \\\n",
       "0  We should take concerns about the health of li...   \n",
       "1  Colts GM Ryan Grigson says Andrew Luck's contr...   \n",
       "2       Trump denies report he ordered Mueller fired   \n",
       "3  France's Sarkozy reveals his 'Passions' but in...   \n",
       "4  Paris Hilton: Woman In Black For Uncle Monty's...   \n",
       "\n",
       "                                             article  \\\n",
       "0  This post is part of Polyarchy, an independent...   \n",
       "1   The Indianapolis Colts made Andrew Luck the h...   \n",
       "2  DAVOS, Switzerland (Reuters) - U.S. President ...   \n",
       "3  PARIS (Reuters) - Former French president Nico...   \n",
       "4  Paris Hilton arrived at LAX Wednesday dressed ...   \n",
       "\n",
       "                                                 url     section  \\\n",
       "0  https://www.vox.com/polyarchy/2016/12/9/138983...         NaN   \n",
       "1  https://www.businessinsider.com/colts-gm-ryan-...         NaN   \n",
       "2  https://www.reuters.com/article/us-davos-meeti...       Davos   \n",
       "3  https://www.reuters.com/article/france-politic...  World News   \n",
       "4  https://www.tmz.com/2016/01/27/paris-hilton-mo...         NaN   \n",
       "\n",
       "        publication  \n",
       "0               Vox  \n",
       "1  Business Insider  \n",
       "2           Reuters  \n",
       "3           Reuters  \n",
       "4               TMZ  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12:05 (5 mins)\n",
    "#df = pd.read_csv('all-the-news-2-1.csv')\n",
    "df= pd.read_csv('../all-the-news-2-1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf2fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26202ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58d91c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2584165, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6be0c7e",
   "metadata": {},
   "source": [
    "### Select a Number of Records to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43130ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 250000\n",
    "np.random.seed(3)\n",
    "inds_to_use = np.random.choice(df.index,num,replace=False)\n",
    "df2 = df.loc[inds_to_use,:]\n",
    "#df2 = df.loc[:num]\n",
    "df2.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "829c9d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e040847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function works on summarized versions of articles\n",
    "## def clean(df):\n",
    "##     start = time.time()\n",
    "##     df['article_words'] = [regexp_tokenize(article,pattern) for article in df['article']]\n",
    "##     df['article_para'] = [article[:120] for article in df['article_words']]\n",
    "##     df['article_title'] = [regexp_tokenize(title,pattern) for title in df['title']]\n",
    "##     df['summary'] = [df['article_title'][i] + df['article_para'][i] for i in range(len(df))]\n",
    "##     \n",
    "##     df['summary_words'] = [[word for word in article if word.isalpha()] for article in df['summary']]\n",
    "##     df['summary_words'] = [func_lemmatize(article) for article in df['summary_words']]\n",
    "##     df['summary_words'] = [[word.lower() for word in article if word.lower() not in stop] for article in df['summary_words']]\n",
    "##     interval = round((time.time() - start)/60,2)\n",
    "##     print(f'That  took {interval} mins.')\n",
    "##     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3b9db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original version\n",
    "def clean(df):\n",
    "    start = time.time()\n",
    "    df['article_words'] = [regexp_tokenize(article,pattern) for article in df['article']]\n",
    "    print('tokenizing done.')  \n",
    "    df['article_words'] = [[word for word in article if word.isalpha()] for article in df['article_words']]\n",
    "    print('isalpha done.')\n",
    "    df['article_words'] = [func_lemmatize(article) for article in df['article_words']]\n",
    "    print('lemmatizing done.')\n",
    "    df['article_words'] = [[word.lower() for word in article if word.lower() not in stop] for article in df['article_words']]\n",
    "    interval = round((time.time() - start)/60,2)\n",
    "    print(f'That  took {interval} mins.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54539b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing done.\n",
      "isalpha done.\n",
      "lemmatizing done.\n",
      "That  took 133.46 mins.\n"
     ]
    }
   ],
   "source": [
    "# Original Function\n",
    "# 09:24\n",
    "df2 = clean(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c88c6ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>url</th>\n",
       "      <th>section</th>\n",
       "      <th>publication</th>\n",
       "      <th>article_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>539903</td>\n",
       "      <td>539903</td>\n",
       "      <td>2017-06-01 00:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>James Vincent</td>\n",
       "      <td>Misfit’s new tool lets you customize your fitn...</td>\n",
       "      <td>Misfit has launched a new tool that lets users...</td>\n",
       "      <td>https://www.theverge.com/circuitbreaker/2017/6...</td>\n",
       "      <td>Tech</td>\n",
       "      <td>The Verge</td>\n",
       "      <td>[misfit, launch, new, tool, let, user, persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255873</td>\n",
       "      <td>255873</td>\n",
       "      <td>2019-07-11 00:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Marcelo Teixeira</td>\n",
       "      <td>Coffee farmers to form legal entity, launch pl...</td>\n",
       "      <td>CAMPINAS, Brazil, July 11 (Reuters) - Particip...</td>\n",
       "      <td>https://www.reuters.com/article/coffee-forum-o...</td>\n",
       "      <td>Non-Cyclical Consumer Goods</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>[campinas, brazil, july, reuters, participants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2403288</td>\n",
       "      <td>2415652</td>\n",
       "      <td>2019-11-06 00:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China supports more aggressive measures to tam...</td>\n",
       "      <td>BEIJING, Nov 6 (Reuters) - China’s Vice Premie...</td>\n",
       "      <td>https://www.reuters.com/article/hongkong-prote...</td>\n",
       "      <td>Cyclical Consumer Goods</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>[beijing, nov, reuters, china, vice, premier, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1328201</td>\n",
       "      <td>1328201</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BRIEF-Selz Capital LLC reports 7.1 pct stake i...</td>\n",
       "      <td>Jan 11 (Reuters) - WPX Energy Inc * Selz Capit...</td>\n",
       "      <td>http://www.reuters.com/article/idUSFWN1F10JT</td>\n",
       "      <td>Funds News</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>[jan, reuters, wpx, energy, inc, selz, capital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2069896</td>\n",
       "      <td>2069896</td>\n",
       "      <td>2017-11-29 22:00:01</td>\n",
       "      <td>2017</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29</td>\n",
       "      <td>Deb Amlen</td>\n",
       "      <td>Sinking It</td>\n",
       "      <td>Wordplay THURSDAY PUZZLE — Today’s puzzle by T...</td>\n",
       "      <td>https://www.nytimes.com/2017/11/29/crosswords/...</td>\n",
       "      <td>crosswords</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[wordplay, thursday, puzzle, today, puzzle, tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Unnamed: 0.1                 date  year  month day  \\\n",
       "0      539903       539903  2017-06-01 00:00:00  2017    6.0   1   \n",
       "1      255873       255873  2019-07-11 00:00:00  2019    7.0  11   \n",
       "2     2403288      2415652  2019-11-06 00:00:00  2019   11.0   6   \n",
       "3     1328201      1328201           2017-01-11  2017    1.0  11   \n",
       "4     2069896      2069896  2017-11-29 22:00:01  2017   11.0  29   \n",
       "\n",
       "             author                                              title  \\\n",
       "0     James Vincent  Misfit’s new tool lets you customize your fitn...   \n",
       "1  Marcelo Teixeira  Coffee farmers to form legal entity, launch pl...   \n",
       "2               NaN  China supports more aggressive measures to tam...   \n",
       "3               NaN  BRIEF-Selz Capital LLC reports 7.1 pct stake i...   \n",
       "4         Deb Amlen                                         Sinking It   \n",
       "\n",
       "                                             article  \\\n",
       "0  Misfit has launched a new tool that lets users...   \n",
       "1  CAMPINAS, Brazil, July 11 (Reuters) - Particip...   \n",
       "2  BEIJING, Nov 6 (Reuters) - China’s Vice Premie...   \n",
       "3  Jan 11 (Reuters) - WPX Energy Inc * Selz Capit...   \n",
       "4  Wordplay THURSDAY PUZZLE — Today’s puzzle by T...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.theverge.com/circuitbreaker/2017/6...   \n",
       "1  https://www.reuters.com/article/coffee-forum-o...   \n",
       "2  https://www.reuters.com/article/hongkong-prote...   \n",
       "3       http://www.reuters.com/article/idUSFWN1F10JT   \n",
       "4  https://www.nytimes.com/2017/11/29/crosswords/...   \n",
       "\n",
       "                       section         publication  \\\n",
       "0                         Tech           The Verge   \n",
       "1  Non-Cyclical Consumer Goods             Reuters   \n",
       "2      Cyclical Consumer Goods             Reuters   \n",
       "3                   Funds News             Reuters   \n",
       "4                   crosswords  The New York Times   \n",
       "\n",
       "                                       article_words  \n",
       "0  [misfit, launch, new, tool, let, user, persona...  \n",
       "1  [campinas, brazil, july, reuters, participants...  \n",
       "2  [beijing, nov, reuters, china, vice, premier, ...  \n",
       "3  [jan, reuters, wpx, energy, inc, selz, capital...  \n",
       "4  [wordplay, thursday, puzzle, today, puzzle, tr...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd5eadc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df2.to_csv('250k_full.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
